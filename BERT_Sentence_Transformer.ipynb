{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bf4d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji\n",
    "\n",
    "from unicodedata import normalize\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from datasets import list_datasets, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23ce56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessar_tweets(tweets):\n",
    "    repetion_pattern = re.compile(r'(.)\\1\\1+')\n",
    "    new_tweets = []\n",
    "    with tqdm(total=len(tweets), colour='green', desc='Processando') as pbar:\n",
    "      for tweet in tweets:\n",
    "          tweet = emoji.demojize(tweet, language='pt')\n",
    "          tweet = tweet.replace('_', ' ')\n",
    "          tweet = normalize('NFKD', tweet).encode('ASCII', 'ignore').decode('ASCII')\n",
    "          tweet = repetion_pattern.sub(r'\\1', tweet)\n",
    "          tweet = re.sub(r'https?://\\w+', '', tweet)\n",
    "          tweet = re.sub(r'@\\w+', ' ', tweet)\n",
    "          tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "          new_tweets.append(tweet.strip())\n",
    "          pbar.update(1)\n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2267b901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando: 100%|\u001b[32m████████████████████████████████████████████████████████████\u001b[0m| 12622/12622 [00:01<00:00, 10104.27it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Carregar os dados\n",
    "data = pd.read_csv('./dataset-merged/dataset_merged.csv')  # Seu arquivo de dados\n",
    "\n",
    "# Dividir os dados em treinamento, teste\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(preprocessar_tweets(data['tweet']), data['hatespeech'],\n",
    "                                                                      train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b53ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\intel/.cache\\torch\\sentence_transformers\\neuralmind_bert-base-portuguese-cased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\intel/.cache\\torch\\sentence_transformers\\neuralmind_bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Carregar o modelo BERT pré-treinado\n",
    "model = SentenceTransformer('neuralmind/bert-base-portuguese-cased')\n",
    "# model = SentenceTransformer('adalbertojunior/distilbert-portuguese-cased')\n",
    "# model = SentenceTransformer('pablocosta/bertabaporu-base-uncased')\n",
    "\n",
    "\n",
    "# Obter embeddings dos textos de treinamento\n",
    "train_embeddings = model.encode(train_texts)\n",
    "test_embeddings = model.encode(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d05c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight=None, max_iter=1500),\n",
    "    'Categorical NB': CategoricalNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(class_weight=None),\n",
    "    'XGBClassifier': XGBClassifier(n_estimators=100),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight=None)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6bea3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation\n",
      "\n",
      "\n",
      "  Classifier: Logistic Regression\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.74       988\n",
      "           1       0.82      0.86      0.84      1537\n",
      "\n",
      "    accuracy                           0.80      2525\n",
      "   macro avg       0.79      0.79      0.79      2525\n",
      "weighted avg       0.80      0.80      0.80      2525\n",
      "\n",
      "F1-macro: 0.7890\n",
      "F1-micro: 0.8016\n",
      "F1-weighted: 0.8002\n",
      "\n",
      "  Classifier: Categorical NB\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.13      0.20       988\n",
      "           1       0.62      0.92      0.74      1537\n",
      "\n",
      "    accuracy                           0.61      2525\n",
      "   macro avg       0.56      0.52      0.47      2525\n",
      "weighted avg       0.57      0.61      0.53      2525\n",
      "\n",
      "F1-macro: 0.4709\n",
      "F1-micro: 0.6079\n",
      "F1-weighted: 0.5294\n",
      "\n",
      "  Classifier: KNN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64       988\n",
      "           1       0.75      0.88      0.81      1537\n",
      "\n",
      "    accuracy                           0.75      2525\n",
      "   macro avg       0.75      0.72      0.72      2525\n",
      "weighted avg       0.75      0.75      0.74      2525\n",
      "\n",
      "F1-macro: 0.7245\n",
      "F1-micro: 0.7521\n",
      "F1-weighted: 0.7434\n",
      "\n",
      "  Classifier: Decision Tree\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       988\n",
      "           1       0.74      0.74      0.74      1537\n",
      "\n",
      "    accuracy                           0.68      2525\n",
      "   macro avg       0.66      0.66      0.66      2525\n",
      "weighted avg       0.68      0.68      0.68      2525\n",
      "\n",
      "F1-macro: 0.6636\n",
      "F1-micro: 0.6796\n",
      "F1-weighted: 0.6796\n",
      "\n",
      "  Classifier: XGBClassifier\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70       988\n",
      "           1       0.80      0.86      0.83      1537\n",
      "\n",
      "    accuracy                           0.78      2525\n",
      "   macro avg       0.77      0.76      0.77      2525\n",
      "weighted avg       0.78      0.78      0.78      2525\n",
      "\n",
      "F1-macro: 0.7659\n",
      "F1-micro: 0.7822\n",
      "F1-weighted: 0.7793\n",
      "\n",
      "  Classifier: Random Forest\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69       988\n",
      "           1       0.78      0.88      0.83      1537\n",
      "\n",
      "    accuracy                           0.78      2525\n",
      "   macro avg       0.78      0.75      0.76      2525\n",
      "weighted avg       0.78      0.78      0.78      2525\n",
      "\n",
      "F1-macro: 0.7599\n",
      "F1-micro: 0.7806\n",
      "F1-weighted: 0.7752\n"
     ]
    }
   ],
   "source": [
    "print('\\nEvaluation\\n')\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "\n",
    "    print(f'\\n  Classifier: {clf_name}\\n')\n",
    "    \n",
    "    if clf_name != 'Categorical NB':\n",
    "        clf.fit(train_embeddings, train_labels)  \n",
    "        pred = clf.predict(test_embeddings)\n",
    "    else:\n",
    "        train_features = np.mean(train_embeddings, axis=1)\n",
    "        train_features = pd.qcut(train_features, q=10, labels=False, duplicates='drop')\n",
    "        train_features = train_features.reshape(-1, 1)\n",
    "        test_features = np.mean(test_embeddings, axis=1)\n",
    "        test_features = pd.qcut(test_features, q=10, labels=False, duplicates='drop')\n",
    "        test_features = test_features.reshape(-1, 1)\n",
    "        \n",
    "        clf.fit(train_features, train_labels)  \n",
    "        pred = clf.predict(test_features)\n",
    "        \n",
    "        \n",
    "    report = classification_report(test_labels, pred, zero_division=0)\n",
    "    \n",
    "    print(report)\n",
    "    \n",
    "    # Calcula a pontuação F1-média\n",
    "    f1_macro = f1_score(test_labels, pred, average='macro')\n",
    "    f1_micro = f1_score(test_labels, pred, average='micro')\n",
    "    f1_weighted = f1_score(test_labels, pred, average='weighted')\n",
    "\n",
    "    print(\"F1-macro: {:.4f}\".format(f1_macro))\n",
    "    print(\"F1-micro: {:.4f}\".format(f1_micro))\n",
    "    print(\"F1-weighted: {:.4f}\".format(f1_weighted))\n",
    "    #ConfusionMatrixDisplay.from_predictions(test_labels, pred)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47ffc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
